#!/bin/csh -f
#
#doc Get rinex files by day number from RINEX ftp archives
#doc
#
# Last modified 99/04/16 by Simon McClusky
# MOD TAH 000317: Added Unavco as an archive source
# MOD SCM 000720: Added IFAG/BKG as an archive source
# MOD RWK 010912: Check only for Hatanaka compressed files at SOPAC to avoid getting duplicates (.o kept for 60 days)
# MOD PT  020409: overhaul of the script to get information about logins, passwords, ftp addresses and
#                 directories as well as the ftp commands from template_ftp and ftp_addresses.
#                 This should remove the need for a user to have to understand and edit this script.
# MOD SCM 020710: Modified to get ftp information from tables/ftp_info rather than com/ftp_addresses.
# MOD KF  040415 Handle non-wild cards for ICC
# MOD KF/RWK 050124: Fix comments/documenation re ftp info.
# MOD SCM 050428: Allow downloadin of sessions other than '0'.
# MOD OCh 051216: Add wget option
# MOD SCM 060905: Allow multiple YYYY, YY, DDDD, and SSSS substitutions in the RINEX ftp directory name.
# MOD SCM 070326: Change to use sh_crx2rnx instead of sh_uncompress.
# MOD SCM 080212: Fix bug in downloading sites whose name starts with a number.
# MOD OCh 080312: Add http(s) possibilities to wget option
# MOD SCM 080715: Change the wildcard for session number to accommodate ftp servers that will not accept wildcard [0-9].
# MOD RWK 090225: Fix for new tsch requirement that numbers with leading zeroes are assumed to be octal.
# MOD OCh 090420: Fix problems with quirks at various archives.
# MOD SCM 100828: Add search of multiple data archives for data.
# MOD TAH 110513  : Added features that detect if the ftp is killed and will re-launch.
# MOD W Szeliga/RWK 120112:  Allow uncompressing for files using bzip2.
# MOD TAH 120306: Remove quotes to avoid 'word too long' when downloading many sites.
# MOD MHM 120418: Add option to bypass uncompressing files.
# MOD RWK 121205: Modify echo help to list all archives,
# MOD TAH 130904: Added option to download into a sub-directory.  Much faster in uncompressing when there are
#                 many rinex files in the current directory.
# MOD SCM 170508: Added ability to download 01D (1 day) 30S (30 sec) rinex 3 files from cddis archive
# MOD MAF 170810: Added trap to use ncftp when "ftp" client is actually "gftp", which interacts with the
#                 server differently to legacy "ftp" and is tricky to use for non-interactive sessions.
# MOD TAH 180419: Added 15S sampling for RINEX3 downloads (mainly UNAVCO). Change 30S to [13]?S.
# MOD TAH 200709: Mod'd to list rinex3 names converted to rinex2 form when -list option used.
# MOD TAH 201106: Fixed cddis -list option so the ftp-like ls output generated.

######################## INSTRUCTIONS #############################
# See if arguments passed
if( $#argv == 0 ) then
  echo "===================================================================================="
  echo " Get RINEX observation files from one or more open archives in tables/ftp_info"
  echo " "
  echo "   Currently supports at least: "
  echo "       CDDIS, SOPAC, IGN-IGS(igni), IGN-Europe (igne), BKG-IGS (bkgi), BKG-Europe(bkge), TIGA"
  echo "       EPNCB, IPGP, NOA, OLG Austria (olg/olgr), GEODAF, ICC Geofons (icc), KREIZ, GPSCOPE "
  echo "       UNAVCO, NGS CORS (cors), USNO, PANGA, WCDA "
  echo "       Geoscience Australia (geoaus), GeoNet New Zealand (geonz), KASI "
  echo "  "
  echo " Usage: sh_get_rinex -archive <archive> -yr <yr> -doy <doy> -ndays <num> -sites <sites>"
  echo "                     -ftp_prog <ftp/ncftp/wget> -list -sd <sites.defaults dir> -expt <expt> -nouncompress"
  echo "                     -subdir -rx2"
  echo "  "
  echo "        <archive>  One or more archives specified with a 'rinex directory' entry in ftp_info [Default sopac] "
  echo "        <yr> 4 char year of nav data requested  [Required] "
  echo "        <doy> 3 char day of year of nav data requested [Required] "
  echo "        <num> Number of consecutive days of data to retrieve [Default 1] "
  echo "        <sites> List of sites to be retrieved from the ftp archive [Required] "
  echo "        <ftp/ncftp/wget> select the ftp program to be used [default ftp]"
  echo "        <list> get list of available files from selected archive"
  echo "        <xcheck>    do not ftp rinex data if xfile exists already [defaul N]"
  echo "        <sites.defaults dir> directory where sites.defaults located"
  echo "        <expt> experinent name used to interogate the sites.default file"
  echo "        <nouncompress> do not uncompress the files "
  echo "        <subdir> creates a temporary subdirectory to speed up uncompress when there are many rinex files in directory"
  echo '        <rx2> only download rinex version 2.? files'
  echo "  "
  echo " Examples: sh_get_rinex -archive sopac cddis  -yr 1998 -doy 235 -ndays 1 -sites algo drao ankr "
  echo "           sh_get_rinex -archive cddis -yr 1998 -doy 235 -ndays 7 -ftp_prog ncftp"
  echo "           sh_get_rinex -archive cddis -yr 1998 -doy 235 -ndays 7 -ftp_prog ncftp -xcheck Y"
  echo "           sh_get_rinex -archive sopac -yr 1998 -doy 235 -list -subdir"
  echo "           sh_get_rinex -archive sopac -yr 2000 -doy 185 -sd ../tables/sites.defaults -expt medi"
  echo "  "
  echo "===================================================================================="
  exit(2)
endif


##################### SET UP DEFAULTS #############################
#
# Setup necessary paths and filenames

set year = ''
set yr = ''
set doy = ''
set log = ''
set numd = 1
set archives = sopac
set rxlist = ''
set save_rxlist = ''
set ftplist = ''
set ftp_prog = 'ftp -inv'
set prog = ''
set doftp = "no"
set xcheck = 'N'
set list = "no"
set expt = ''
set sd = ''
set pday = 0
set wlogin = ''
set wgetsite = ''
set wgetoptions = ''
set nouncompress = 0
set subdir = N
set rx2 = N

##################### DECIPHER COMMAND LINE #######################
while ($#argv > 0 )
  set input = ( $argv )
  switch($input[1])
#   case -a:
#    case -arc:
#    case -archive:
#      set archive  = $input[2]
#    breaksw
# Mod SCM 100828 allow sh_get_rinex to loop over archives when downloading data.
    case -a*:
       set archives = (`echo $argv | cut -d- -f2`); shift archives
    breaksw
    case -n:
    case -nday:
    case -ndays:
      set numd = $input[2]
    breaksw
    case -y*:
      set year = $input[2]
# Variable yr[1] = 4 char yr, yr[2] = 2 char yr, yr[3] = 1 char yr
      set yr = `sh_year -year $year`
    breaksw
    case -d:
    case -doy:
      set doy = $input[2]
    breaksw
    case -si*:
       set rxlist = (`echo $argv | cut -d- -f2`); shift rxlist
    breaksw
    case -ftp_prog:
      set ftp_prog = $input[2]
      if ($ftp_prog == 'ftp') set ftp_prog = 'ftp -inv'
    breaksw
    case -xcheck:
      set xcheck  = $input[2]
    breaksw
    case -l*:
      set list = "yes"
    breaksw
    case -sd:
      set sd  = $input[2]
    breaksw
    case -expt:
      set expt  = $input[2]
    breaksw
    case -nouncompress:
      set nouncompress  = 1
    breaksw
    case -su*:
      set subdir = Y
    breaksw
    case -rx2*:
      set rx2 = Y
    breaksw
  endsw
  if ( $#argv > 0 ) shift argv
end
alldone:

# Added by MAF (2017-08-10, MIT) to check if ftp is aliased or linked to gftp on local machine
#Â Appended by MAF (2018-06-07, MIT) to check if ftp is missing, e.g. on macOS High Sierra
if ( `echo $ftp_prog | awk '{print $1}'` == 'ftp' && `ftp -v << quit` != '' ) then
  if ( `which ncftp` =~ '*ncftp' ) then
    set ftp_prog = 'ncftp'
    echo 'ftp command aliased or linked to gftp; trying ncftp instead'
  else if ( `which wget` =~ '*wget' ) then
    set ftp_prog = 'wget'
    echo 'ftp command aliased or linked to gftp; trying wget instead'
  endif
else if ( `echo $ftp_prog | awk '{print $1}'` == 'ftp' && `which ftp` !~ '*ftp' ) then
  if ( `which ncftp` =~ '*ncftp' ) then
    set ftp_prog = 'ncftp'
    echo 'ftp command not found; trying ncftp instead'
  else if ( `which wget` =~ '*wget' ) then
    set ftp_prog = 'wget'
    echo 'ftp command not found; trying wget instead'
  endif
endif

##################### READ THE FTP_INFO TEMPLATE ############################
#
# Loop over all the list archives to be checked for matching data
foreach archive ($archives)
  set ftp_info = `sh_get_ftp_info -archive $archive -type rinex`

  while ($#ftp_info > 0 )
    set input = ( $ftp_info )
    switch($input[1])
      case -ftpsite:
        set ftpsite  = $input[2]
      breaksw
      case -ftplogin:
        set ftplogin  = (`echo $ftp_info | cut -d- -f2`); shift ftplogin
      breaksw
      case -ftpdir:
        set ftpdir  = $input[2]
      breaksw
      case -ftpcmd:
        set ftpcmd  = (`echo $ftp_info | cut -d% -f2`); shift ftpcmd
       breaksw
      case -wgetsite:
        set wgetsite  = $input[2]
      breaksw
      case -wlogin:
        set wlogin  = (`echo $ftp_info | cut -d- -f2`); shift wlogin
      breaksw
    endsw
    if ( $#ftp_info > 0 ) shift ftp_info
  end

  echo "Information extracted from ftp_info"
  echo "########################################"
  echo "ftpsite $ftpsite"
  echo "ftplogin $ftplogin"
  echo "ftpdir $ftpdir"
  echo "ftpcmd $ftpcmd"
  if ( $wgetsite != '' ) echo "wgetsite $wgetsite"
  if ( `echo $wlogin | wc -w` > 0  ) echo "wlogin $wlogin"
  echo "########################################"

  # Added by MAF (2020-08-19, MIT)
  # MOD TAH 200920: Changed to check both cddis and cddismgex (as in rest of script)
  #if ( "$archive" == 'cddis' ) then
  if ( `echo $archive | cut -c 1-5` == 'cddis'  ) then
    # Test which program to use for download
    if ( -e `which curl` ) then  # curl exists (preferred due to better directory listing and wget is not native on macOS)
      set prog = 'curl -s -f -L'
    else if ( -e `which wget` ) then  # wget exists
      set prog = 'wget -q'
    else  # Neither curl nor wget available
      echo 'Neither curl nor wget available to download RINEX files from CDDIS.'
    endif
  endif
  # END: Added by MAF (2020-08-19, MIT)

##################### GET THE JOB DONE ############################
#
# Set timestamp hostname variable
  set ts = "`hostname`:`date +"%H%M%S"`"
  set log = `date "+get_rinex_${archive}_%y%m%d:%H%M.log"`
  touch $log
  echo "# sh_get_rinex log: Time stamp $ts" >> $log
  echo "# Created `date`" >> $log

# Check all required info given.
  if ( ${year} == '' ||  ${doy} == '' ) then
    echo "Not all required fields given -- yr: $year doy: $doy --Stop"
    exit(2)
  endif

# If sites.defaults given get site list from this file based on expt given
  if ( $sd != '' ) then
   set rxlist = `sh_get_defaults -token ftprnx -expt $expt -yr $yr[1] -doy $doy -sd $sd -expt $expt`
  endif

# Check if ncftp is requested
  if ( `echo $ftp_prog | awk '{print $1}'` == 'ncftp' ) then
    if (`echo $ftpcmd | awk '{print $1}'` == 'ftp') then
      if ( "$ftpsite" =~ '*.ucsd.edu' ) then
        set ftpcmd = `echo $ftp_prog -p $ftplogin[2] $ftpsite`
      else
        set ftpcmd = `echo $ftp_prog $ftpsite`
      endif
      echo "-ftp_prog = ncftp requested, ftpcmd now: $ftpcmd"
    endif
  endif

# Check if wget is requested
  if ( `echo $ftp_prog | awk '{print $1}'` == 'wget' ) then
      if ( `echo $wlogin | wc -w` == 0 ) set wlogin = `echo $ftplogin`
      if ( $wgetsite == '' ) set wgetsite = `echo ftp://$ftpsite`
      set ftpcmd = `echo $ftp_prog`
      echo "-ftp_prog = wget requested, ftpcmd now: $ftpcmd"
  endif

# Save original rxlist incase it get messed with later and we need to reset it.
  set save_rxlist = ($rxlist)

#
# Set up loop on days
  @ sday = `echo "ibase=10; ${doy} - 1" | bc`
  @ count = `echo "ibase=10; ${numd}" | bc`

  while ( $count )
    set sday = `echo $sday |  awk '{printf "%03d \n", $1+1}'`
    @ count = $count - 1

# Set up the ftp script
    if ( `echo $archive | cut -c 1-5` == 'cddis' ) then
      cat /dev/null >! tmp.get.$ts
    else if (`echo $ftpcmd | awk '{print $1}'` == 'ftp') then
      echo "user $ftplogin" >! tmp.get.$ts
      echo "binary" >> tmp.get.$ts
      set getcmd = 'get'
    else if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
      cat /dev/null >! tmp.get.$ts
      if ((`echo $wgetsite | awk -F: '{print $1}'` == 'https') && ($sday == $doy)) set wgetoptions = "--no-check-certificate $wgetoptions"
    else
      echo "binary" >! tmp.get.$ts
      set getcmd = 'get -f -z'
    endif

# Get a list of available files from the archive for this day
    if ( $list == yes ) then
      set directory = `echo $ftpdir | sed -e s/"YYYY"/$yr[1]/g | sed -e s/"YY"/$yr[2]/g | sed -e s/"DDD"/${sday}/g`
      echo "directory = `echo $ftpdir | sed -e s/"YYYY"/$yr[1]/g | sed -e s/"YY"/$yr[2]/g | sed -e s/"DDD"/${sday}/g`"
#     MOD TAH 201106: Use curl code to get *?list file from cddis and then create a file
#     with colums to look like ftp ls command.
      if ( `echo $archive | cut -c 1-5` == 'cddis' && "$prog" != '' ) then
        set directory = `echo $ftpdir | sed -e s/"YYYY"/$yr[1]/g | sed -e s/"YY"/$yr[2]/g | sed -e s/"DDD"/${sday}/g`
        set listcddis = "http.${sday}.listing"
        if ( `echo $prog | awk '{print $1}'` == 'curl' ) then
          if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
            echo "Downloading directory listing for $yr[1]-$sday from CDDIS (https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/) via authenticated secure HTTP with curl..."
            $prog -b .urs_cookies -c .urs_cookies -n -o "$listcddis" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list" ||\
             $prog -b .urs_cookies -c .urs_cookies -n --ciphers 'DEFAULT@SECLEVEL=1' -o "$listcddis" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list"
          else if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 711 ) then  # Use anonymous secure FTP (requires curl version >= 7.11.0)
            if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 720 ) then  # Use newer "--ssl" option
              set ssl_opt = '--ssl'
            else  # Use older "--ftp-ssl" option
              set ssl_opt = '--ftp-ssl'
            endif
            echo "Downloading directory listing for $yr[1]-$sday from CDDIS (ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/) via anonymous secure FTP with curl..."
            $prog -u anonymous:$ftplogin[2] $ssl_opt -o "$listcddis" "ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/pub//'`/" ||\
             $prog -u anonymous:$ftplogin[2] $ssl_opt --ciphers 'DEFAULT@SECLEVEL=1' -o "$listcddis" "ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/pub//'`/"
          endif
        else if ( `echo $prog | awk '{print $1}'` == 'wget' ) then
          if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
            echo "Downloading directory listing for $yr[1]-${sday} from CDDIS (https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/) via authenticated secure HTTP with wget..."
            $prog --load-cookies .urs_cookies --save-cookies .urs_cookies --keep-session-cookies --auth-no-challenge -O "$listcddis" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list"
          # wget doesn't seem to be able to list directory contents over FTP
          #else if ( `wget --version | awk '{if (NR == 1) print substr($3,1,4)}' | sed 's/\.//g'` >= 118 ) then  # Use anonymous secure FTP (requires wget version >= 1.18)
          #  echo "Downloading directory listing for $yr[1]-${sday} from CDDIS (ftps://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/) via anonymous secure FTP with wget..."
          #  $prog --ftp-user anonymous --ftp-password $ftplogin[2] -O "$listfile" "ftps://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/"
          endif
        endif
#       MOD TAH 101106: Code above creates http.listing &listcddis with file name and size.
#-r--r--r--    1 99       33         533929 Oct 20 00:28 019b2920.20d.Z
#ankr2920.20d.Z                                843383
        awk '{printf("-r--r--r--    1 99       33 %10d Jan 00 2000 %s \n",$2,$1)}' $listcddis >! cddis.${sday}.list
        set listfile = "cddis.${sday}.list"
        \rm $listcddis
#     MOD TAH 201106: continue with else if for other site that use ftp ls.
      else if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
        if (`echo $wgetsite | awk -F: '{print $1}'` == 'ftp') then                    ##OCh
#         if ($sday == $doy) set wgetoptions = ($wgetoptions -nr -i -)
          if ($sday == $doy) set wgetoptions = ($wgetoptions --no-remove-listing -i -)

          set directory = ($wgetsite$directory/)
          echo $directory >! tmp.list.$ts
          set listfile = .listing
        else                                                                          ##OCh
          set listfile = 'curl.lst'                                                   ##OCh
# MOD TAH 200709: Allow for rinex3 names as well (use egrep not grep and look for two patterns)
          curl -k ${wgetsite}${directory}/ | egrep "${sday}.\.${yr[2]}[od]|${yr[1]}${sday}" | awk '{print substr($0,index($0,".Z")-12,14)}' > ${listfile}##OCh
        endif                                                                         ##OCh
      else
        if (`echo $ftpcmd | awk '{print $1}'` == 'ftp') then
          echo "user $ftplogin" >! tmp.list.$ts
          echo "binary" >> tmp.list.$ts
        else
          echo "binary" >! tmp.list.$ts
        endif
        echo 'cd '$directory  >> tmp.list.$ts
        echo 'ls -la' >> tmp.list.$ts
        echo 'quit' >> tmp.list.$ts
        set listfile =  tmp.list.log
      endif
      if ( $listfile != 'curl.lst' ) then
        $ftpcmd $wgetoptions < tmp.list.$ts >! tmp.list.log ##OCh
      endif
      cat $listfile | grep ${sday}..${yr[2]} >! list_${yr[1]}_${sday}.log
# MOD TAH 200709: Check for rinex3 names and convert to rinex2 form (quick fix until things get re-writen)
      grep crx.gz $listfile | awk '{newn=tolower(substr($NF,1,4)) substr($NF,17,3) "0." substr($NF,15,2) "d.gz"} {gsub($NF,newn)} {print $0}' >>  list_${yr[1]}_${sday}.log
      \rm -r tmp.list.$ts tmp.list.log $listfile index.html*
      echo "Created rinex list file: list_${yr[1]}_${sday}.log"
      goto next
    endif
    # Added by MAF (2020-08-19, MIT)
    if ( `echo $archive | cut -c 1-5` == 'cddis' && "$prog" != '' ) then
      set directory = `echo $ftpdir | sed -e s/"YYYY"/$yr[1]/g | sed -e s/"YY"/$yr[2]/g | sed -e s/"DDD"/${sday}/g`
      set listfile = '.listing'
      if ( `echo $prog | awk '{print $1}'` == 'curl' ) then
        if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
          echo "Downloading directory listing for $yr[1]-$sday from CDDIS (https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/) via authenticated secure HTTP with curl..."
          $prog -b .urs_cookies -c .urs_cookies -n -o "$listfile" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list" ||\
           $prog -b .urs_cookies -c .urs_cookies -n --ciphers 'DEFAULT@SECLEVEL=1' -o "$listfile" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list"
        else if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 711 ) then  # Use anonymous secure FTP (requires curl version >= 7.11.0)
          if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 720 ) then  # Use newer "--ssl" option
            set ssl_opt = '--ssl'
          else  # Use older "--ftp-ssl" option
            set ssl_opt = '--ftp-ssl'
          endif
          echo "Downloading directory listing for $yr[1]-$sday from CDDIS (ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/) via anonymous secure FTP with curl..."
          $prog -u anonymous:$ftplogin[2] $ssl_opt -o "$listfile" "ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/pub//'`/" ||\
           $prog -u anonymous:$ftplogin[2] $ssl_opt --ciphers 'DEFAULT@SECLEVEL=1' -o "$listfile" "ftp://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/pub//'`/"
        endif
      else if ( `echo $prog | awk '{print $1}'` == 'wget' ) then
        if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
          echo "Downloading directory listing for $yr[1]-${sday} from CDDIS (https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/) via authenticated secure HTTP with wget..."
          $prog --load-cookies .urs_cookies --save-cookies .urs_cookies --keep-session-cookies --auth-no-challenge -O "$listfile" "https://cddis.nasa.gov`echo $directory | sed 's/pub/archive/'`/*?list"
        # wget doesn't seem to be able to list directory contents over FTP
        #else if ( `wget --version | awk '{if (NR == 1) print substr($3,1,4)}' | sed 's/\.//g'` >= 118 ) then  # Use anonymous secure FTP (requires wget version >= 1.18)
        #  echo "Downloading directory listing for $yr[1]-${sday} from CDDIS (ftps://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/) via anonymous secure FTP with wget..."
        #  $prog --ftp-user anonymous --ftp-password $ftplogin[2] -O "$listfile" "ftps://gdc.cddis.eosdis.nasa.gov`echo $directory | sed 's/\/pub//'`/"
        endif
      endif
    endif
    # END: Added by MAF (2020-08-19, MIT)
    if ($sday == $doy) set wgetoptions = ($wgetoptions -v -N)

# See if the files already exist
#  echo '# Touch' >! tmp.t.$ts

# If rxlist is set to download "all" sites we need to reset it to "all"
# since it was prolly messed up by the download reporting part of the process
    if ( $save_rxlist[1] == 'all' ) then
      set rxlist = $save_rxlist
    endif

# Get sites included in the list (rxlist) to be retrieved
    foreach site ( `echo $rxlist` )

# Now should be able to use a generic directory name defined in ftp_info and
# simply substitute the correct year and day-of-year for YYYY and DDD
      if ( $sday != ${pday} || $archive == "cors" || $archive == "olgr") then
        set directory = `echo $ftpdir | sed s/"YYYY"/$yr[1]/g | sed s/"YY"/$yr[2]/g | sed s/"DDD"/${sday}/g | sed s/"SSSS"/${site}/g`
        echo "directory = `echo $ftpdir | sed s/"YYYY"/$yr[1]/g | sed s/"YY"/$yr[2]/g | sed s/"DDD"/${sday}/g | sed s/"SSSS"/${site}/g`"
#      set directory = `echo $ftpdir | sed s/"YYYY"/$yr[1]/ | sed s/"YY"/$yr[2]/  | sed s/"YY"/$yr[2]/ | sed s/"DDD"/${sday}/ | sed s/"SSSS"/${site}/ `
        if (`echo $ftpcmd | awk '{print $1}'` != 'wget' && `echo $archive | cut -c 1-5` != 'cddis' ) echo 'cd '$directory  >> tmp.get.$ts
        set pday = ${sday}
      endif
      if ( $site != 'all' ) then
# Modified to allow session # other than 0 to be downloaded. SCM 050428
#      set lc_site = ${site}${sday}0.${yr[2]}
#      set UC_site = `echo ${site}${sday}0.${yr[2]} | awk '{print toupper($1)}'`
        set lc_site = ${site}
        set UC_site = `echo ${site} | awk '{print toupper($1)}'`
       if ( ! -e ${lc_site}${sday}0.${yr[2]}o && ! -e ${lc_site}${sday}0.${yr[2]}o.Z && ! -e ${lc_site}${sday}0.${yr[2]}o.gz && \
	     ! -e ${lc_site}${sday}0.$yr[2]}o.bz2 \
          && ! -e ${lc_site}${sday}0.${yr[2]}d && ! -e ${lc_site}${sday}0.${yr[2]}d.Z && ! -e ${lc_site}${sday}0.${yr[2]}d.gz && \
             ! -e ${lc_site}${sday}0.${yr[2]}d.bz2 ) then
# PT020730: only get the rinex file if the xfile doesn't exist and/or xcheck = N
# Actually this does not work because day directory name can be quite different.
          set x_exist = `\ls ../${sday}/x${site}* |& grep -v 'No match' | wc -l ` >& /dev/null	### of no use with year extension ##OCh
# TAH050416: Added spaces after if( and between )then (loops confused otherwise)
          if( $xcheck == 'N' ||  $x_exist == "0" ) then
            # Added by MAF (2020-08-19, MIT)
            if ( `echo $archive | cut -c 1-5` == 'cddis' && "$prog" != '' ) then
              if ( `echo $prog | awk '{print $1}'` == 'curl' ) then
                if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
                  if ( "$rx2" == 'N' ) then
                    grep -E "^${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|^${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                     awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "url = \"https://cddis.nasa.gov%s/%s\"\n-O\n",dir,$1}' >> tmp.get.$ts
                  endif
                  grep -E "${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                   grep "^${lc_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                    awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "url = \"https://cddis.nasa.gov%s/%s\"\n-O\n",dir,$1}' >> tmp.get.$ts
                else if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 711 ) then  # Use anonymous secure FTP (requires curl version >= 7.11.0)
                  if ( $rx2 == "N" ) then
                    grep -E " ${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx| ${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                     awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "url = \"ftp://gdc.cddis.eosdis.nasa.gov%s/%s\"\n-O\n",dir,$NF}' >> tmp.get.$ts
                  endif
                  grep -E "${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                   grep " ${lc_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                    awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "url = \"ftp://gdc.cddis.eosdis.nasa.gov%s/%s\"\n-O\n",dir,$NF}' >> tmp.get.$ts
                endif
              else if ( `echo $prog | awk '{print $1}'` == 'wget' ) then
                if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
                  if ( $rx2 == "N" ) then
                    grep -E "^${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|^${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                     awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "https://cddis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
                  endif
                  grep -E "${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                   grep "^${lc_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                    awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "https://cddis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
                #else if ( `wget --version | awk '{if (NR == 1) print substr($3,1,4)}' | sed 's/\.//g'` >= 118 ) then  # Use anonymous secure FTP (requires wget version >= 1.18)
                #  if ( $rx2 == "N" ) then
                #    grep -E "^${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|^${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                #     awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "ftps://gdc.cddis.eosdis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
                #  endif
                #  grep -E "${UC_site}.*_${yr[1]}${sday}.*_01D_15S.*\.crx|${UC_site}.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                #   grep "^${lc_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                #    awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "ftps://gdc.cddis.eosdis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
                endif
              endif
            # END: Added by MAF (2020-08-19, MIT)
            else if ( $archive == "bkge" ) then
              if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                echo "wget $wgetoptions -a $log -O  ${lc_site}${sday}0.${yr[2]}d.Z $wgetsite$directory/"\""${UC_site}${sday}0.${yr[2]}D.Z"\" >> tmp.get.$ts
                echo "chmod u+w ${lc_site}${sday}0.${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
              else
                echo $getcmd ${lc_site}${sday}0.${yr[2]}d.Z ${lc_site}${sday}0.${yr[2]}d.Z >> tmp.get.$ts
              endif
# TAH050429: Added replaced get with mget for lines below.
            else if ( $archive == "sopac" || $archive == "kreiz" || $archive == "unavco" || $archive == "cors" ) then
              if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${lc_site}${sday}[0-9].${yr[2]}d.Z"\" >> tmp.get.$ts
                echo "chmod u+w ${lc_site}${sday}[0-9].${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
              else
# TAH130214: Replaced ? with * in session named.  Reported by Bob Smalley that ? does not work at SOPAC as of 2/13//2013. *
#            shoukd work will others as well.
                echo mget ${lc_site}${sday}'[0-9]'.${yr[2]}'d'.Z >> tmp.get.$ts
              endif
            else if ( $archive == "gahirt" ) then
              if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${UC_site}${sday}*.${yr[2]}d.Z"\" >> tmp.get.$ts
                echo "chmod u+w ${UC_site}${sday}*.${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
                echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${lc_site}${sday}*.${yr[2]}d.Z"\" >> tmp.get.$ts
                echo "chmod u+w ${lc_site}${sday}*.${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
              else
                echo mget ${UC_site}${sday}'*'.${yr[2]}'d'.Z >> tmp.get.$ts  ##OCh
                echo mget ${lc_site}${sday}'*'.${yr[2]}'d'.Z >> tmp.get.$ts  ##OCh
              endif
            else if ( $archive == "icc") then
              if (${yr[1]} >= "2004") then
                if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                  echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${UC_site}${sday}[0-9].${yr[2]}E"\" >> tmp.get.$ts
                  echo "chmod u+w ${UC_site}${sday}[0-9].${yr[2]}E >&! /dev/null" >> tmp.get.$ts
                else
                  echo mget ${UC_site}${sday}'?'.${yr[2]}'E'   >> tmp.get.$ts  ##OCh
                endif
              else
                if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                  echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${UC_site}${sday}[0-9].${yr[2]}d.Z"\" >> tmp.get.$ts
                  echo "chmod u+w ${UC_site}${sday}[0-9].${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
                else
                  echo mget ${UC_site}${sday}'?'.${yr[2]}'d'.Z >> tmp.get.$ts  ##OCh
                endif
              endif
            else if ( $archive == "geodaf" ) then  ##OCh
              if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${lc_site}${sday}*.${yr[2]}d.Z"\" >> tmp.get.$ts
                echo "chmod u+w ${lc_site}${sday}*.${yr[2]}d.Z >&! /dev/null" >> tmp.get.$ts
              else
                echo mget ${lc_site}${sday}'*'.${yr[2]}'d'.Z >> tmp.get.$ts
              endif
            else
              if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
                ###########################################################OCh
                #
                if (`echo $wgetsite | awk -F: '{print $1}'` == 'ftp') then
                  echo "wget $wgetoptions -a $log $wgetsite$directory/"\""${lc_site}${sday}[0-9].${yr[2]}[od]*"\" >> tmp.get.$ts
                else
                  foreach rfile (`curl -k ${wgetsite}${directory}/ | grep "${lc_site}${sday}.\.${yr[2]}[od]" | awk '{print substr($0,index($0,".Z")-12,14)}'`)
                    echo "wget --no-check-certificate $wgetoptions -a $log ${wgetsite}${directory}/"\""${rfile}"\" >> tmp.get.$ts
                  end
                endif
                #
                ###########################################################OCh
                echo "chmod u+w ${lc_site}${sday}[0-9].${yr[2]}[od]* >&! /dev/null" >> tmp.get.$ts
              else
                echo mget ${lc_site}${sday}'?'.${yr[2]}'o*' >> tmp.get.$ts  ##OCh
                echo mget ${lc_site}${sday}'?'.${yr[2]}'d*' >> tmp.get.$ts  ##OCh
                if ( $rx2 == "N" ) then
                  echo mget ${UC_site}'*_'${yr[1]}${sday}'*_01D_30S*.crx*' >> tmp.get.$ts
                  echo mget ${UC_site}'*_'${yr[1]}${sday}'*_01D_15S*.crx*' >> tmp.get.$ts
                endif
              endif
            endif
#          echo touch ${site}${sday}0.${yr[2]}o.Z >> tmp.t.$ts
          endif
        endif
      else
        # Added by MAF (2020-08-19, MIT)
        if ( `echo $archive | cut -c 1-5` == 'cddis' && "$prog" != '' ) then
          if ( `echo $prog | awk '{print $1}'` == 'curl' ) then
            if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
              if ( "$rx2" == 'N' ) then
                grep -E "_${yr[1]}${sday}.*_01D_15S.*\.crx|_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                 awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "%s -b .urs_cookies -c .urs_cookies -n -R -O \"https://cddis.nasa.gov%s/%s\"\n",prog,dir,$1}' >> tmp.get.$ts
              endif
              foreach rx2_site ( `grep "${sday}[0-9]\.${yr[2]}d\.Z" $listfile | awk '{print substr($1,1,4)}' | sort -u` )
                grep -E "`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_15S.*\.crx|`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                 grep "^${rx2_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                  awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "url = \"https://cddis.nasa.gov%s/%s\"\n-O\n",dir,$1}' >> tmp.get.$ts
              end
            else if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 711 ) then  # Use anonymous secure FTP (requires curl version >= 7.11.0)
              if ( $rx2 == "N" ) then
                grep -E "_${yr[1]}${sday}.*_01D_15S.*\.crx|_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                 awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "url = \"ftp://gdc.cddis.eosdis.nasa.gov%s/%s\"\n-O\n",dir,$1}' >> tmp.get.$ts
              endif
              foreach rx2_site ( `grep "${sday}[0-9]\.${yr[2]}d\.Z" $listfile | awk '{print substr($1,1,4)}' | sort -u` )
                grep -E "`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_15S.*\.crx|`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                 grep "^${rx2_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                  awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "url = \"ftp://gdc.cddis.eosdis.nasa.gov%s/%s\"\n-O\n",dir,$1}' >> tmp.get.$ts
              end
            endif
          else if ( `echo $prog | awk '{print $1}'` == 'wget' ) then
            if ( -e ~/.netrc ) then  # Use authenticated secure HTTP
              if ( $rx2 == "N" ) then
                grep -E "_${yr[1]}${sday}.*_01D_15S.*\.crx|_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
                 awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "https://cddis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
              endif
              foreach rx2_site ( `grep "${sday}[0-9]\.${yr[2]}d\.Z" $listfile | awk '{print substr($1,1,4)}' | sort -u` )
                grep -E "`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_15S.*\.crx|`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
                 grep "^${rx2_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
                  awk -v dir=`echo $directory | sed 's/pub/archive/'` '{printf "https://cddis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
              end
            #else if ( `wget --version | awk '{if (NR == 1) print substr($3,1,4)}' | sed 's/\.//g'` >= 118 ) then  # Use anonymous secure FTP (requires wget version >= 1.18)
            #  if ( $rx2 == "N" ) then
            #    grep -E "_${yr[1]}${sday}.*_01D_15S.*\.crx|_${yr[1]}${sday}.*_01D_30S.*\.crx" $listfile | \
            #     awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "ftps://gdc.cddis.eosdis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
            #  endif
            #  foreach rx2_site ( `grep "${sday}[0-9]\.${yr[2]}d\.Z" $listfile | awk '{print substr($1,1,4)}' | sort -u` )
            #    grep -E "`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_15S.*\.crx|`echo $rx2_site | tr '[:lower:]' '[:upper:]'`.*_${yr[1]}${sday}.*_01D_30S.*\.crx" tmp.get.$ts >& /dev/null || \
            #     grep "^${rx2_site}${sday}[0-9]\.${yr[2]}d\.Z" $listfile | \
            #      awk -v dir=`echo $directory | sed 's/\/pub//'` '{printf "ftps://gdc.cddis.eosdis.nasa.gov%s/%s\n",dir,$1}' >> tmp.get.$ts
            #  end
            endif
          endif
        # END: Added by MAF (2020-08-19, MIT)
        else if ( $archive == "bkge" ) then
             if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
               echo "wget $wgetoptions -a $log $wgetsite$directory/"\""*D.Z"\" >> tmp.get.$ts
               echo "chmod u+w *D.Z >&! /dev/null" >> tmp.get.$ts
             else
               echo 'mget *D.Z' >> tmp.get.$ts
             endif
        else if ( $archive == "sopac" || $archive == "kreiz" ) then
             if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
               echo "wget $wgetoptions -a $log $wgetsite$directory/"\""*d.Z"\" >> tmp.get.$ts
               echo "chmod u+w *d.Z >&! /dev/null" >> tmp.get.$ts
             else
               echo 'mget *d.Z' >> tmp.get.$ts
             endif
        else if ( $archive ==  "unavpbo" || $archive ==  "wcda" ) then
             if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
               echo "wget $wgetoptions -a $log $wgetsite$directory/"\""*0.??d.Z"\" >> tmp.get.$ts
               echo "chmod u+w *0.??d.Z >&! /dev/null" >> tmp.get.$ts
             else
               echo mget '*0.??d.Z' >> tmp.get.$ts
             endif
        else
             if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
               ###########################################################OCh
               #
               if (`echo $wgetsite | awk -F: '{print $1}'` == 'ftp') then
                 echo "wget $wgetoptions -a $log $wgetsite$directory/"\""*[od].Z"\" >> tmp.get.$ts
               else
                 echo "curl -k ${wgetsite}${directory}/"
                 foreach rfile (`curl -k ${wgetsite}${directory}/ | grep "....[0-9]\{3\}.\.[0-9]\{2\}[od]\.Z" | awk '{print substr($0,index($0,".Z")-12,14)}'`)
                   echo "wget --no-check-certificate $wgetoptions -a $log ${wgetsite}${directory}/"\""${rfile}"\" >> tmp.get.$ts
                 end
               endif
               #
               ###########################################################OCh
               echo "chmod u+w *[od].Z >&! /dev/null" >> tmp.get.$ts
             else
               echo mget '*o.Z' >> tmp.get.$ts
               echo mget '*d.Z' >> tmp.get.$ts
             endif
        endif
      endif
    end
    if (`echo $ftpcmd | awk '{print $1}'` == 'wget' || `echo $archive | cut -c 1-5` == 'cddis') then
      #set ftplist = ` awk '/wget/{print $NF}' tmp.get.$ts  | awk -F/ '{print substr($NF,2,4)}' | sort -u` ##OCh
      set ftplist = `grep -v '^\-O' tmp.get.$ts | tr -d '"' | awk -v FS='/' '{print substr($NF,1,4)}' | sort -u` ##OCh
    else
#   set ftplist = `grep get tmp.get.$ts | awk '{printf "%.4s ",$2}'`
      set ftplist = `awk '/get/{printf "%.4s\n",$2}' tmp.get.$ts | sort -u`      ##OCh
    endif

    if ( $#ftplist <= 0 ) then
       echo "All requested rinex files exist. No sites to download: EXIT"
# SCM Don't exit here there may be more days to download!
#     exit
    endif

    if ( $#ftplist >= 1 ) then

      if (`echo $ftpcmd | awk '{print $1}'` != 'wget' && `echo $archive | cut -c 1-5` != 'cddis') echo 'quit' >> tmp.get.$ts
      cat tmp.get.$ts >> $log
      echo ' ' >> $log
      echo '--------------------' >> $log

# MOD TAH 130904: See if we will use subdirectory
      if( $subdir == Y ) then
#         Create name and create
          set subd = rnx.${doy}.${ts}
          echo "Creating $subd for download and uncompress" >> $log
          if( ! -e $subd ) mkdir $subd
          cd $subd
          ln -s ../tmp.get.$ts .
      endif
#################### IN SUBDIR if -subdir option used #####################

      if (`echo $ftpcmd | awk '{print $1}'` != 'wget' && `echo $archive | cut -c 1-5` != 'cddis' ) then
# MOD TAH 980520: Repeat the get.
      set cnt = 5
      set try = 0
      while ( $cnt )
        @ cnt = $cnt - 1
        @ try = $try + 1
        echo "Try ${try}: Getting rinex data for day ${sday} from ${archive} archive (${ftpsite})"
# MOD TAH 120306: Do not put in " " or word can be too long
        echo Attempting to download sites: ${ftplist}

###### THE ACTUAL FTP EXECUTION IS HERE #######################
        echo $ftpcmd
        # Edited by MAF (2017-08-10, MIT) to set exit status explicitly with "ftp_stat" variable
        #$ftpcmd < tmp.get.$ts | grep -v '^220' >! tmp.log.$ts
        $ftpcmd < tmp.get.$ts | grep -v '^220' >! tmp.log.$ts && set ftp_stat = 0 || set ftp_stat = 1
        #echo "FTP STAT $?"  # Commented to avoid error with "$?" variable on some csh implementations by MAF (2016-02-01, MIT)
        echo "FTP STAT $ftp_stat"
        if( $subdir == N ) then
            cat tmp.log.$ts >> $log
        else
            cat tmp.log.$ts >> ../$log
        endif

#  See if we got connected to ftp server OK
        grep 'Not connected' tmp.log.$ts >! tmp.test.$ts
        set chk = `cat tmp.test.$ts | wc -l`
        if ( $chk != 0 ) echo "Could not connect to ftp server ${ftpsite} - Wait 2 minutes and try again"
#  MOD TAH 110420: Make sure the command completed OK if the length is more than zero.
        set chk2 = 1
        # Edited by MAF (2017-08-10, MIT) to use exit status defined by "ftp_stat" to determine if ncftp exited
        if ( `echo $ftpcmd | awk '{print $1}'` == 'ncftp' ) then
          if ( $ftp_stat == 0 ) set chk2 = 1
        else
          if( -s tmp.log.$ts )set chk2 = `grep '^221 ' tmp.log.$ts | wc -l`
        endif
        ls -l tmp.log.$ts
        echo "File content"
        cat tmp.log.$ts
        echo "END file"
        echo "chk2 $chk2"
        if( $chk2 == 0 ) then
           echo "End of ftp 221 line not found - Wait 2 minutes and try again"
#          Check to see if last file transferred OK:
           set laststart = `grep '^150 ' tmp.log.$ts | awk '{print NR, $(NF-2)}' | tail -n -1 `
           set lastend = `grep '^226 ' tmp.log.$ts | awk '{print NR}' | tail -n -1`
#          See is fewer 'Transfer complete' lines (226) than 'Opening lines' (150)
           set lenl = `echo $laststart | wc -w`
           echo "lenl $lenl ; Lastend = $lastend"
           echo "Laststart = $laststart"

           if( $lenl > 0 ) then
              echo "By word $laststart[1] and $laststart[2]"
              if( $lastend < $laststart[1]) then
                 echo "Transfer of $laststart[2] not complete: Removing file"
                 \rm -f $laststart[2]
              endif
           endif
        endif

#  See if we have to many ftp connections open to this server
        grep 'exceeded your maximum number of FTP connections' tmp.log.$ts >! tmp.test1.$ts
        set chk1 = `cat tmp.test1.$ts | wc -l`
        if ( $chk1 != 0 ) echo "Exceded max ftp connections to this server ${ftpsite} - Wait 2 minutes and try again"
        if( $chk == 0 && $chk1 == 0 && $chk2 > 0 ) then
          set cnt = 0
        else
          if ( $chk1 != 0 ) then
 	       echo "Script will wait indefinitly for ftp server connection."
 	       set cnt = 5
 	  endif
          sleep 120
        endif
      end
      else
        if ( `echo $archive | cut -c 1-5` == 'cddis' ) then
          if ( `echo $prog | awk '{print $1}'` == 'curl' ) then
            if ( -e ~/.netrc ) then
              echo "Getting rinex data for day $sday from $archive archive (https://cddis.nasa.gov) using `echo $prog | cut -d ' ' -f 1`"
              $prog -w "curl downloaded %{url_effective} (%{size_download} B) in %{time_total} s at %{speed_download} B/s\n" -b .urs_cookies -c .urs_cookies -n -R -O -K tmp.get.$ts >> $log ||\
               $prog -w "curl downloaded %{url_effective} (%{size_download} B) in %{time_total} s at %{speed_download} B/s\n" -b .urs_cookies -c .urs_cookies -n --ciphers 'DEFAULT@SECLEVEL=1' -R -O -K tmp.get.$ts >> $log
            else
              echo "Getting rinex data for day $sday from $archive archive (ftp://gdc.cddis.eosdis.nasa.gov) using `echo $prog | cut -d ' ' -f 1`"
              if ( `curl --version | awk '{if (NR == 1) print substr($2,1,4)}' | sed 's/\.//g'` >= 720 ) then  # Use newer "--ssl" option
                set ssl_opt = '--ssl'
              else  # Use older "--ftp-ssl" option
                set ssl_opt = '--ftp-ssl'
              endif
              $prog -w "curl downloaded %{url_effective} (%{size_download} B) in %{time_total} s at %{speed_download} B/s\n" -u anonymous:$ftplogin[2] $ssl_opt -R -O -K tmp.get.$ts >> $log ||\
               $prog -w "curl downloaded %{url_effective} (%{size_download} B) in %{time_total} s at %{speed_download} B/s\n" -u anonymous:$ftplogin[2] $ssl_opt --ciphers 'DEFAULT@SECLEVEL=1' -R -O -K tmp.get.$ts >> $log
            endif
          else if ( `echo $prog | awk '{print $1}'` == 'wget' ) then
            if ( -e ~/.netrc ) then
              echo "Getting rinex data for day $sday from $archive archive (https://cddis.nasa.gov) using `echo $prog | cut -d ' ' -f 1`"
              $prog -a $log --load-cookies .urs_cookies --save-cookies .urs_cookies --keep-session-cookies --auth-no-challenge -N -i tmp.get.$ts
            else if ( `wget --version | awk '{if (NR == 1) print substr($3,1,4)}' | sed 's/\.//g'` >= 118 ) then  # Use anonymous secure FTP (requires wget version >= 1.18)
              echo "Getting rinex data for day $sday from $archive archive (ftps://gdc.cddis.eosdis.nasa.gov) using `echo $prog | cut -d ' ' -f 1`"
              $prog -a $log --ftp-user anonymous --ftp-password $ftplogin[2] -N -i tmp.get.$ts
            endif
          endif
          chmod u+w *_${yr[1]}*_01D_{15,30}S*.crx* *.${yr[2]}d.Z >&! /dev/null
        else
          echo Attempting to download sites: ${ftplist}
          csh tmp.get.$ts	# WGET TAKES PLACE HERE
          echo "  "
          echo "Download log saved in file: "$log
          grep saved $log | grep "....$sday" | grep -v listing
          echo "  "
        endif
      endif

# MOD TAH 0501416: If sites = all, extract the actual names of sites
      if( $rxlist[1] == 'all' ) then
        if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
          if (`echo $wgetsite | awk -F: '{print $1}'` == 'ftp') then                                             ##OCh
	    grep "==> RETR .* done" $log | grep $sday |  tr-d '`'\' | awk '{print substr($7,1,4)}' > rxlist.tmp  ##OCh
          else                                                                                                   ##OCh
            grep saved $log | grep $sday | tr -d '`'\' | awk '{print substr($5,1,4)}' > rxlist.tmp               ##OCh
          endif                                                                                                  ##OCh
          set rxlist = `cat rxlist.tmp | sort -u`                                                                ##OCh
          rm -f rxlist.tmp                                                                                       ##OCh
        else
          set rxlist = `grep local $log | awk '{print substr($2,1,4)}' | sort -u`
        endif
        echo "Selection all: Actual download "$rxlist
      endif

#
#   Now uncompress the rinex files and delete files with zero size.
      sh_casefold -dir d -files [A-Z]???${sday}?.${yr[2]}*  >& /dev/null
      echo rxlist = $rxlist ##OCh
# MOD OCH 080317 dealing with rxlist being 'all' or a real list of sites was a problem.
# multiple sessions were not taken into account
      foreach rfile ( `ls ????${sday}?.${yr[2]} '*_'${yr[1]}${sday}'*_01D_[13]?S*.crx.*'` )
        if ( -z ${rfile} ) rm -f ${rfile} # an empty rinex file is always a problem, even if it has not been downloaded by this script
      end
      if (! $nouncompress ) then
        if ($rxlist[1] == 'all') then
          echo "Extracting with all list"
          ( \ls -d  ????${sday}?.${yr[2]}o.Z > /dev/null ) > & /dev/null
          if ( $status == 0 ) sh_uncompress -f ????${sday}?.${yr[2]}o.Z
          ( \ls -d  ????${sday}?.${yr[2]}o.gz > /dev/null ) > & /dev/null
          if ( $status == 0 ) gunzip -f ????${sday}?.${yr[2]}o.gz
          ( \ls -d  ????${sday}?.${yr[2]}o.bz2 > /dev/null ) > & /dev/null
          if ( $status == 0 ) bunzip2 -f ????${sday}?.${yr[2]}o.bz2
          ( \ls -d  ????${sday}?.${yr[2]}d.bz2 > /dev/null ) > & /dev/null
          if ( $status == 0 ) sh_crx2rnx -f ????${sday}?.${yr[2]}d.bz2
          ( \ls -d  ????${sday}?.${yr[2]}d.gz > /dev/null ) > & /dev/null
          if ( $status == 0 ) sh_crx2rnx -f ????${sday}?.${yr[2]}d.gz
          ( \ls -d  ????${sday}?.${yr[2]}d.Z > /dev/null ) > & /dev/null
          if ( $status == 0 ) sh_crx2rnx -f ????${sday}?.${yr[2]}d.Z
          ( \ls -d  ????${sday}?.${yr[2]}d > /dev/null ) > & /dev/null
          if ( $status == 0 ) crx2rnx ????${sday}?.${yr[2]}d
          (\ls -d  *_${yr[1]}${sday}*_01D_[13]?S*.crx > /dev/null ) >& /dev/null ; set s = $status ; echo crx $s
          if ( $s == 0 ) then
            sh_rename_rinex3 -f *_${yr[1]}${sday}*_01D_[13]?S*.crx -r
            sh_crx2rnx -f ????${sday}?.${yr[2]}d
          endif
          (\ls -d  *_${yr[1]}${sday}*_01D_[13]?S*.crx.gz > /dev/null ) >& /dev/null ; set s = $status ; echo crx.gz $s
          if ( $s == 0 ) then
            sh_rename_rinex3 -f *_${yr[1]}${sday}*_01D_[13]?S*.crx.gz -r
            sh_crx2rnx -f ????${sday}?.${yr[2]}d.gz
          endif

        else    # $rxlist != 'all'
          echo "Extracting by list `date`"
          foreach site ( `echo $rxlist` )
            set lc_site = ${site}
            set UC_site = `echo ${site} | awk '{print toupper($1)}'`
            echo "Site: $lc_site $UC_site"
#            echo "Decompressing $site `date`"
            ( \ls -d  ${site}${sday}?.${yr[2]}o.Z > /dev/null ) > & /dev/null
            if ( $status == 0 ) sh_uncompress -f ${site}${sday}?.${yr[2]}o.Z
            ( \ls -d  ${site}${sday}?.${yr[2]}o.gz > /dev/null ) > & /dev/null
            if ( $status == 0 ) gunzip -f ${site}${sday}?.${yr[2]}o.gz
            ( \ls -d  ${site}${sday}?.${yr[2]}o.bz2 > /dev/null ) > & /dev/null
            if ( $status == 0 ) bunzip2 -f ${site}${sday}?.${yr[2]}o.bz2
            ( \ls -d  ${site}${sday}?.${yr[2]}d.bz2 > /dev/null ) > & /dev/null
            if ( $status == 0 ) sh_crx2rnx -f ${site}${sday}?.${yr[2]}d.bz2
            ( \ls -d  ${site}${sday}?.${yr[2]}d.Z > /dev/null ) > & /dev/null
            if ( $status == 0 ) sh_crx2rnx -f ${site}${sday}?.${yr[2]}d.Z
            ( \ls -d  ${site}${sday}?.${yr[2]}d.gz > /dev/null ) > & /dev/null
            if ( $status == 0 ) sh_crx2rnx -f ${site}${sday}?.${yr[2]}d.gz
            ( \ls -d  ${site}${sday}?.${yr[2]}d > /dev/null ) > & /dev/null
            if ( $status == 0 ) crx2rnx ${site}${sday}?.${yr[2]}d
            (\ls -d  ${UC_site}*_${yr[1]}${sday}*_01D_[13]?*.crx > /dev/null ) >& /dev/null ; set s = $status
            if ( $s == 0 ) then
              sh_rename_rinex3 -f ${UC_site}*_${yr[1]}${sday}*_01D_[13]?*.crx -r
              sh_crx2rnx -f ${site}${sday}?.${yr[2]}d
            endif
            (\ls -d  ${UC_site}*_${yr[1]}${sday}*_01D_[13]?*.crx.gz > /dev/null ) >& /dev/null ; set s = $status
            if ( $s == 0 ) then
              sh_rename_rinex3 -f ${UC_site}*_${yr[1]}${sday}*_01D_[13]?*.crx.gz -r
              sh_crx2rnx -f ${site}${sday}?.${yr[2]}d.gz
            endif
          end
        endif   # $rxlist = 'all'
      endif

      \rm tmp.1.$ts tmp.get.$ts tmp.test.$ts tmp.test1.$ts tmp.t.$ts tmp.log.$ts $listfile >& /dev/null

    endif

##################### subdir option: Copy back and remove tmp directory ################
    if( $subdir == Y ) then
#      move rxfiles
       ls
       echo Pattern
       ls -l ????????.${yr[2]}[od]*
       \mv ????????.${yr[2]}[od]* ..
       cd ..
#      Now remove direcory contents
       echo "Removing $subd contents" >> $log
       ls $subd/* >> $log
       \rm -r $subd/*
     endif

# Tell the user what RINEX files were downloaded
    if ( $log != '' ) then
# MOD TAH 050418: Added test because both sopac and cors list local
#   line even when file does not exist.
    if (`echo $ftpcmd | awk '{print $1}'` == 'wget') then
        if (`echo $wgetsite | awk -F: '{print $1}'` == 'ftp') then                                           ##OCh
	    grep "==> RETR .* done" $log  | grep $sday | awk '{printf "%s ",$7}' | tr -d '`'\' > ftpdown.tmp ##OCh
        else                                                                                                 ##OCh
            grep saved $log  | grep $sday | awk '{printf "%s ",$5}' | tr -d '`'\' > ftpdown.tmp              ##OCh
        endif                                                                                                ##OCh
        set ftpdown = `cat ftpdown.tmp`                                                                      ##OCh
        rm -f ftpdown.tmp                                                                                    ##OCh
    else
#     if( $archive != 'cors' && $archive != 'sopac' && $archive != 'unavco' ) then
        if( $archive != 'cors' && $archive != 'sopac' ) then                                                 ##OCh
          set ftpdown = `grep "local:" $log  | grep $sday | awk '{printf "%s ",$4}'`
        else
          set ftpdown = `grep "Opening" $log | grep $sday | awk '{printf "%s ",$8}'`
        endif
      endif
      echo "Sucessfully downloaded:" $ftpdown
    else
    echo "All RINEX files exist nothing to download"
  endif

# Jump to here
next:

# End loop over days
  end
\rm tmp.1.$ts tmp.list.$ts tmp.get.$ts tmp.test.$ts tmp.test1.$ts tmp.t.$ts tmp.log.$ts $listfile >& /dev/null

# End loop over archives
# MOD TAH 161118: Need to reset this value to get cd line written to get command
set pday = 0  # Reset pday to default initial value
end

# MOD TAH 170217: Removed extra end (generates error output, but is harmless at end
#end


# Thats all.
exit(1)
