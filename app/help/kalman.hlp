KALMAN: Discussion of VLBI Kalman filter
 
KALMAN FILTERING DISCUSSION 
----------------------------
 
1. Introduction 
--------------- 
 
    This documents outlines the operation and the use the Kalman filter 
analysis software developed at MIT.  We first describe the algorithms used in 
the filter.  We then discuss the MIT implementation of these algorithms.  The 
discussion of SOLVK, its ancillary programs, its file structures, and the 
commands which are used to run the filter are contained in separate help
files.
    The Kalman filter can viewed as sequential weighted-least-solution with 
one added feature.  At each step of the solution, some elements of the
covariance matrix are increased.  This additional variance (and possibly
covariances as well) allow the parameter estimate to change with each new data
set added to the solution.  If the variance added for a particular parameter
is very large then the estimate of the parameter will be determined solely
from the data for this step.  The "arc" parameters in the sequential solutions
implemented in SOLV2, SOLV3 and MIT SOLVE correspond to this case.  If the
additional variance is very small (or zero) then the parameter is estimated 
from the current data set and all previous data sets.  The "global" parameters
in sequential solutions corresponds to this case.  The Kalman filter
implements a solution technique for which the variance added to the parameter 
covariance matrix is with in the range such that the parameter estimate can 
change between arcs but is still constrained by the previously used data sets.
In SOLVK the data sets are formed from the data at each epoch in the VLBI 
experiment.  As with all sequential solutions, the solution is carried out in 
two parts; the forward solution which yields the estimates of the global
parameters, and a back solution which is used to obtain the estimates of the
arc parameters. 
    In the Kalman filter software the "arc" parameters are called the "Markov"
parameters.  All parameters can be markov in the SOLVK implementation.  The 
"global" parameters are called the "deterministic" parameters.  The markov
parameters are used to represent the behavior of the stochastic processes 
i.e., quantities which have no fixed values and their behavior can be only
described statistically.  Typical parameters which can be treated as
stochastic are the parameters used to represent the behaviors of the clocks 
and the atmospheres.  For completeness in the code all other parameters can be
treated as stochastic parameters.  Two types of the stochastic processes can be 
used to model the behaviors of the clocks and atmospheres.  These processes 
are a random walk and an integrated random walk.  A random walk is generated
by adding uncorrelated random numbers together.  The progression of the sum as
the random numbers are added is a random walk.  For the model of a clock we 
can imagine the frequency of the clock changing randomly (with no correlation 
between the changes) with time.  Since the time measured by the clock is
obtained by integrating its frequency, the error in the clock time will be a
random walk.  The integrated random walk is the process generated by
integrating a random walk.  For the clock case an integrated random is
generated if the errors in the frequency are a random walk. 
    Each of these processes has specific statistical properties which can be
used to determine if a real process matches either of these models.  These
statistical properties are given by the expectation of the errors in the
process at different times.  These errors are called the process noise. (The
process noise could be the error in the clock time reading or the difference
of the zenith delay from some model of its variations.) For simplicity here we
will discuss a discrete time process, i.e., one for which the random changes
occur at discrete times, for example, every second.  (We can reduce the 
discrete case to the continuous case by reducing the time between the changes 
to an infintesimal time interval.) For the random walk, the expectation of the
product of the process noise at two times or the covariance at, t(i) and t(j),
is var(ran)*t(i) where var(ran) is the "step" variance i.e., the variance of  
the random numbers added at each step, and t(i) and t(j) are the elapsed times  
(in units of the step interval, in our case one second) since the value of the  
clock time was known.  We should notice that the covariance at the times  
depends only on the earlier of the two times.  In practice, since we never  
know the clock time, the elapsed times are measured from a time at which an 
apriori variance is given to the clock time.  When t(i) equals t(j) the 
covariance is the variance.  These characteristics of the process lead to a 
correlation function of the process, rho(i,j), [=covariance divided by the  
square root of the variances] given by rho(i,j) = t(i)/sqrt[t(i)*t(j)].  For  
the integrated random walk, the covariance between the process noise at times 
t(i) and t(j) is (var(int)*t(i)^3)/3 where var(int) is the step variance of 
the integrated random walk.  The variance of the process noise increases with 
time cubed where as for the random walk the variance increases linearly with  
time.   
    Neither the hydrogen maser or atmospheric delay can be modeled simply by a  
random walk, an integrated random walk, or a combination of these two 
processes.  The variance of a hydrogen maser clock error is approximately 
proportional to time squared for periods of 100 seconds to one day which  
results in its Allan variance being constant.  The hydrogen maser variance  
increases more rapidly than a random walk but not as rapidly as an integrated 
random walk.  The variance of atmospheric zenith delays due to water vapor  
tend to increase with time to some power less than one.  The variations of the  
properties of water vapor variations are much more variable than those for  
hydrogen masers.  The Kalman filter cannot model the precise statistical  
properties of these two processes and, hence, we must compromise in our 
analysis.  [The random walk and integrated random walks can be reduced to an  
uncorrelated generating function which allows them to easily used in the  
sequential filter.] The way we comprise our modeling of the hydrogen masers is  
to combine a random walk and integrated random walk in such a way that for  
some interval of time the model matches the behavior of hydrogen masers.  We  
typically match the 1d-14 performance of the hydrogen maser at time intervals 
of 20 minutes.  The estimates of the deterministic parameters are relatively  
insensitive to this choice of time interval. (An interested user may wish to  
investigate this topic.) (In Section 3 we discuss how the performance of the  
clocks is given in the filter.) For water vapor variations we typically model 
the process with only a random walk (which allows more long period (>1 hour)  
variations than we would expect from the from "real" water vapor variations.  
In addition to the random walk and integrated random walks, we also allow the 
clocks and atmospheres to have random white (uncorrelated) noise.  The white  
noise is processed by adding its contribution to the covariance matrix of the 
observables.  (This procedure is equivalent to estimating the white noise 
contributions with the filter but is more easily implemented.  These white  
noise contributions are similar to the reweighting constants in SOLVE except  
that we also take into account the correlations between the contributions for 
different baselines to the same site.) The white noise contributions we use 
are very small (~2 ps^2) and are used to model the short period variations of 
water vapor.  
    For the other parameters which SOLVK can estimate only the random walk  
process has been implemented.  (We will probably add integrated random walks  
to some of these other parameters in the future.  In particular, polar motion 
and UT1-AT are more likely to be better represented by integrated random walks  
than random walks.) In general, the only stochastic parameters in the 
solutions are the clocks and atmospheres.  These other stochastic parameters  
are included mainly for experimental purposes.  
    The application of Kalman filtering is not just restricted to analysis of 
individual VLBI experiments.  A Kalman filter can be used to combine the  
results individual experiments.  Such an approach has been adopted in the 
GLOBK program.  Here the solution vectors and covariance matrices from  
individual SOLVK solutions are combined to obtain optimal estimates of such 
quantities as source positions, site positions, site velocities, nutation 
series coefficients etc.  For the global kalman filter, there are Markov and  
deterministic parameters as in SOLVK.  Here, however, a Markov parameter may  
be a site position, or nutation angles.  Again, the basic markov processes  
used are random walks, and integrated random walks.  Although for polar 
motion, UT1 and nutation angles we have allowed first-order Markov processes  
as well which allow the Chandler wobble to be explicitly included in the  
stochastic processes (Morabito, Eubanks, and Steppe, Kalman filtering earth 
orientation changes, submitted to IAU Symposium No. 128, The earth's rotation 
and reference frames for geodesy and geodynamics.)  A detailed discussion of  
GLOBK is contained in GLOBK::HELP.
 
2. KALMAN FILTER ANALYSIS PACKAGE.
----------------------------------
 
    The Kalman filter analysis package is composed of a number of programs  
which read data bases, carry out Kalman filter solutions, allow the analysis  
of the solution, and update databases.  Here we describe the main programs in 
this suite of programs, and the operation and purpose of each of these  
programs.  The Kalman filter analysis package is a totally self contained set 
of programs (i.e., all links with previous analysis programs have be severed).
The basic data files of these new programs is the KalObs (KALman filter 
OBServation) files.  The KalObs files contain much of the same of information 
as SOLVE or SOLV3 files.  However, there are a large enough number of 
differences that to combine the types of files into one structure would have  
lead to a particularly cumbersome file.  For example, a kalman filter does not  
need information about clock polynomial coefficients and epochs which consume 
about 0.5K of storage in conventional analysis programs.  A Kalman filter 
needs to have information about Markov statistics (which consume a reasonable 
amount of the Kalman filter file space).  This information would unnecessarily  
increase the size of a conventional analysis program.  However, the most  
important reason for the new files, was so that information, not needed in  
computational intense parts of the filter software, could be separated into 
parts of the KalObs files which would not need to be read into these programs.  
This allows large MSEG sizes for these programs, and thus allows them to run  
as fast as a possible with EMA on an F-series HP1000. 
    The KalObs files are single files which contain all the information needed  
to process a VLBI experiment with a Kalman filter.  They are composed of four 
(multi-record) blocks.  These blocks are: 
VALUES -- contains essential header information which is used in all of the 
          Kalman filter programs (See OBS_VALUES.FTNI)
NAMES  -- contains site, monument and source names and the names of any files 
          containing source structure information. (See OBS_NAMES.FTNI) 
APR    -- contains apriori site and source positions and other miscellaneous  
          positional information (See OBS_APR.FTNI) 
DATA   -- contains the data records, one set per observation in the data base.
          (See OBS_DATA.FTNI) 
There are also utility subroutines which allow each of the blocks (or all of  
the blocks) to be read and written, and will open, create or close KalObs 
files (See KalObs_handler.ftn).  These routines can be easily called and check  
for correct version dates of the files so that obsolete versions of the KalObs  
files can not be accidentally processed.  These routines are also set to  
compute the size of each of the blocks, so that modification of the files is  
very transparent to the user.  (There is also spare space in each of the  
blocks so that new information can be added, with out obsoleting previously 
read KalObs files). Software also exists which can be used to produce 
directory list of KalObs files on disk, with any obsolete files marked (see 
KDL below). 
    In addition to the KalObs files, there are several other semi-permanent 
files introduced with this analysis package.  These are the SOLVK back  
solution files (BakFiles) and the Global files (GlbFiles).  The BakFiles  
contain the output of a SOLVK back Kalman Filter solution and are self  
contained in that neither the KalObs file from which they were generated or 
the SOLVK files (which are true scratch files) need to be available for them  
to interpreted.  The BakFiles are processed by the plotting program PLTSL and 
the Kalman filter Analysis program KALAN. (KALAN does require that the KalObs 
file be available, since the results of the analysis are stored in the KalObs 
file).  The GlbFiles contain the solution and covariance matrix of the  
"geodetic" parameters from either a SOLVK or GLOBK solution.  Again these 
files are self contained and can be used by GLOBK and GLIST without the KalObs  
file being available. 
 
3. PROCESSING KALOBS FILES
--------------------------
    The main programs which are used to process KalObs files are listed below 
in an order in which the programs might be used. Unless other wise noted, all 
of the programs below can be run from either CI or FMGR command files and do  
not require any interactive input. Each of these programs also has its own  
help file which explains how to run the programs and any inputs which are 
required. 
 
READIN -- Reads a data base and produces a KalObs file which can be used by 
          other programs. 
READOB -- Allows the contents a KalObs file to examined and output to files by  
          other programs (such as PLOT) 
AMBI   -- Resolves group delay ambiguities in batch mode using initially the  
          single band delays. 
CALC_ION -- Computes the group, phase, rate ionospheric delay corrections from  
          a X- and S-band KalObs files. (Any other frequency combination would
          also work)
UPDATE_DB -- Allows a data base to be updated with new ambiguities, editing,  
          and ionospheric corrections to be stored in the data base from a  
          KalObs file 
UPDATE_PMU -- Allows the polar motion, UT1 tables to be updated in a KalObs 
          file. 
DBLIST   -- Lists active data bases, and produces a CI command file which can 
          be used to read all active data bases into KalObs files.  (Some 
          editing of the command file is needed to specify disk LU's and
          some changes to experiments to those which are stored in the data 
          base. 
KDL      -- Directory of KalObs files.  File masks can be specified in the  
          same way as they are for the CI DL command.  Output can be sent to a  
          disk file which can then be edited to make a command file to  
          process the KalObs files with SOLVK.
SOLVK    -- The Kalman filter analysis program for single VLBI experiments
GLOBK    -- The Kalman filter analysis program for combining many VLBI  
          experiments together. Also outputs global files, which can be 
          processed, combined with other global files, by GLOBK.
          Carries out both forward and back solution Kalman filter runs.
GLRED    -- Reduces the number of parameters in a global solution.  This  
          program can be used to produce global files with reduced parameter  
          sets (e.g., the global files from SOLVK may have had earth tide 
          parameters estimated.  GLRED can be used to produce a new set of  
          global files with the earth tide parameters set to their apriori  
          values.  GLRED can also be used to do the Global Back solution much 
          quicker, in general, than the back solution option in GLOBK but at  
          the expense of some rigor in the computation of the standard  
          deviations of the parameter estimates.
GDL      -- Directory of Global files.  Similar to KDL, except searches for 
          global files. The output from this program can be used as the list  
          input file for GLOBK. 
KALAN    -- Analyses the results of a SOLVK solution  (Back solution must be  
          run with SOLVK.) Computes Allan standard deviations of Markov 
          parameters, edits data, and computes atmosphere Markov statistics 
          using the delay rate residuals. 
EXTRACT  -- Extracts information for any ASCII file which has some repeating  
          structure.  Generally used to get information from either SOLVK or  
          GLOBK back solutions.  For example, an ascii file containing the  
          nutation angle estimates as a function of time can be extracted from  
          a GLOBK back solution using this program.  Program can also be used 
          to generate a table of final site and source position estimates from
          a GLOBK output (if it is spooled to a file).  
BLSUM    -- Specific extraction software which will produce a values file of
          baseline lengths from multiple SOLVK runs (if spooled to a file)  
          sorted by baseline (but in the same time order as the experiments 
          were processed) and a summary file which has one line per baseline  
          which contains its mean length, rms of values about the mean, 
          average rate of change and rms about slope, time span of  
          measurements and the mean epoch of the experiments. 
          
4. NOTES ON SPOOLING
--------------------
 
    SOLVK and GLOBK print their results to physical LU's.  On the A900 it 
should be possible to spool results printed to LU 6 (or any other LU with 
spooling enabled).  At the end of multiple runs, the spool file can then be 
copied to standard file in the system and analysed. If software spooling of 
this nature is not available on your system, then you can try "real" spooling,
i.e., output to an LU which then can be rewound and copied to a disk file.  At  
MIT, we spool solutions to a magnetic tape, or to a PC (with a hard disk) 
which is used to capture the solution.  The captured file is then down loaded 
back onto a HP disk file.  Most of the Kalman filter software has been written  
for unattended operation running from either CI or FMGR command files.  
Development of a spooling system, so that results can latter be examined with 
programs such as EXTRACT and BLSUM, will greatly enhance the productivity of  
the Kalman filter programs. 
    This approach to spooling (using a physical LU such as a magnetic tape or 
PC) has been adopted because SOLVK processes each experiment in separate runs.  
Since an overnight batch run of SOLVK on typically 100 to 200 experiments will  
produce a solution file which contains 30,000-60,000 lines, any file output 
which requires reading to the end of a file so that the next solution can be  
concatenated onto the file is not very efficient.  We are currently 
investigating outputting results to individual files and then using the MERGE 
program to combine the files.  This approach would require twice as much disk 
space as the current approach but does avoid trying up either a tape drive or 
a PC.  Any suggestions on spooling would be welcome.
 
5. SOME EXAMPLES
----------------
 
    Below we give some examples of how the Kalman filter software programs can  
be applied.  The following CI command file can be used to analyse a VLBI  
experiment from after its CALC'd to generally the final solution is one run 
without any analyst time. 
 
Command file: PROCESS_VLBI_EXP.CMD
* 
* CI command file to process a VLBI experiment from CALC to "final" answers.
* 
* NOTE: Hard wired file names here could be replaced with CI runstring  
* characters $1-$9.  Thus one command file could be used for all experiments. 
* 
* Our experience at MIT, indicates that the following command file should 
* produce a very good final answer. Since this is all done in batch an  
* analyst can use the time while these are running to look at the small number
* of problematic experiments. 
 
sl 20 1     * Log reports to system console (any other lu could be used)
sl  8 8     * spool the results to LU 8 for analysis later. 
 
cn 8 rw     * Rewind 8
 
* Readin the latest versions of the X and S-band data bases (The I in the 
* KalObs file name denotes IRIS experiment) 
readin,,20,!87MAY11X,0,K7511I::53,,`IRIS 354` 
readin,,20,!87MAY11S,0,K7511S::53,,`IRIS 354` 
 
* Remove ambiguities from X and S-band data bases 
ambi, K7511I::53
ambi, K7511S::53
 
* Do a preliminary run of solvk to kill any really bad data.
* For 90% of experiments the steps below are not needed.
solvk,,8,20,K7511I::53, markov_edit.cmd 
kalan, out=8, Bak=B7511I::53, edit=20 
solvk,,8,20,K7511S::53, markov_edit.cmd 
kalan, out=8, Bak=B7511S::53, edit=20 
 
* Compute the ionospheric delay for group and phase delays
calc_ion, K7511I::53, K7511S::53 gr 
 
* Now do final run just use the X-band with ion correction  (with final edit  
* check and get the markov statistics for the atmospheres)  
solvk,,8,20,K7511I::53, markov_final.cmd
kalan, out=8, bak=b7511I::53, edit=4.0, atm=0.75=0.05=10
 
solvk,,8,20,K7511I::53, markov_final.cmd
 
* That should be all.  Just update the database so that we do not need to 
* do all this work again later. Here we are updating the group ambiguities
* (G), the ionospheric delays (I) and the editing (E).  For the X-band
* database we are also adding some comments on the analysis stored in the 
* file hist_7511I.txt.
 
update_db, K7511I::53, gie hist_7511I.txt 
update_db, K7511S::53, gie
 
cn 8 eo    * Mark END of File 
cn 8 rw 
co 8 K7511I_analysis.dat  * CI file, save for future reference. 
cn 8 rw 
 
 
